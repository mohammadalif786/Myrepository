{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9537604,"sourceType":"datasetVersion","datasetId":2058865},{"sourceId":517278,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":407934,"modelId":425802}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, Dataset\nfrom torchvision import datasets, transforms, models\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\nimport matplotlib.pyplot as plt\n\n# --- 1. Configuration and Hyperparameters ---\nDATA_DIR = \"/kaggle/input/multi-cancer/Multi Cancer/Multi Cancer/Cervical Cancer\"\nMODEL_PATH = \"/kaggle/input/mobilenet1/pytorch/default/1/mobilenet_v2-7ebf99e0.pth\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")\n\nNUM_EPOCHS = 10\nBATCH_SIZE = 32\nLEARNING_RATE = 0.001\n\ntry:\n    NUM_CLASSES = len(os.listdir(DATA_DIR))\n    print(f\"Found {NUM_CLASSES} classes.\")\nexcept FileNotFoundError:\n    print(f\"FATAL ERROR: The directory '{DATA_DIR}' was not found. Please check your dataset path.\")\n    exit()\n\n# --- 2. Data Preprocessing and Loading ---\ntrain_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nval_test_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nfull_dataset = datasets.ImageFolder(DATA_DIR)\nclass_names = full_dataset.classes\n\ntotal_size = len(full_dataset)\ntrain_size = int(0.70 * total_size)\nval_size = int(0.15 * total_size)\ntest_size = total_size - train_size - val_size\n\ntrain_subset, val_subset, test_subset = random_split(\n    full_dataset, [train_size, val_size, test_size],\n    generator=torch.Generator().manual_seed(42)\n)\n\nclass CustomDataset(Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n    def __len__(self):\n        return len(self.subset)\n\ntrain_dataset = CustomDataset(train_subset, transform=train_transforms)\nval_dataset = CustomDataset(val_subset, transform=val_test_transforms)\ntest_dataset = CustomDataset(test_subset, transform=val_test_transforms)\n\ndataloaders = {\n    'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2),\n    'val': DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2),\n    'test': DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n}\ndataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset), 'test': len(test_dataset)}\nprint(f\"Dataset sizes: {dataset_sizes}\")\nprint(f\"Class names: {class_names}\")\n\n# --- 3. Model Definition ---\nmodel = models.mobilenet_v2(weights=None)\ntry:\n    model.load_state_dict(torch.load(MODEL_PATH))\n    print(\"Pre-trained weights loaded successfully from file.\")\nexcept Exception as e:\n    print(f\"Could not load weights from {MODEL_PATH}. Error: {e}. Training from scratch.\")\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.classifier = nn.Sequential(\n    nn.Dropout(0.2),\n    nn.Linear(model.last_channel, NUM_CLASSES)\n)\n\nmodel = model.to(DEVICE)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)\n\n# --- 4. Training Function ---\ndef train_model(model, criterion, optimizer, dataloaders, num_epochs):\n    since = time.time()\n    best_acc = 0.0\n    train_acc_history, val_acc_history = [], []\n    best_model_path = \"/kaggle/working/best_model_weights.pth\"\n\n    for epoch in range(num_epochs):\n        print(f'\\nEpoch {epoch}/{num_epochs - 1}' + '\\n' + '-' * 10)\n        for phase in ['train', 'val']:\n            model.train() if phase == 'train' else model.eval()\n            running_loss, running_corrects = 0.0, 0\n            for inputs, labels in dataloaders[phase]:\n                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                    _, preds = torch.max(outputs, 1)\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            (train_acc_history if phase == 'train' else val_acc_history).append(epoch_acc.item())\n            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                torch.save(model.state_dict(), best_model_path)\n                print(\"Best validation accuracy! Model saved.\")\n    time_elapsed = time.time() - since\n    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best Val Acc: {best_acc:.4f}')\n    return model, train_acc_history, val_acc_history, best_model_path\n\n# --- 5. Evaluation Function ---\ndef evaluate_model(model, dataloader, class_names):\n    model.eval()\n    all_labels, all_preds, all_probs = [], [], []\n    start_time = time.time()\n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n            outputs = model(inputs)\n            probs = nn.functional.softmax(outputs, dim=1)\n            _, preds = torch.max(outputs, 1)\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n    test_time = time.time() - start_time\n    print(f\"\\nTesting complete in {test_time:.2f}s\")\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n    try:\n        if NUM_CLASSES == 2:\n            auc = roc_auc_score(all_labels, np.array(all_probs)[:, 1])\n        else:\n            auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='weighted')\n    except ValueError:\n        auc = 0.0\n    print(\"\\n--- Evaluation Metrics ---\")\n    print(f\"Overall Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(f\"AUC: {auc:.4f}\")\n    return test_time\n\n# --- 6. Main Execution ---\nif __name__ == '__main__':\n    model, train_acc, val_acc, best_model_path = train_model(model, criterion, optimizer, dataloaders, num_epochs=NUM_EPOCHS)\n    print(\"\\n--- Loading best model for evaluation ---\")\n    model.load_state_dict(torch.load(best_model_path))\n    print(\"\\n--- Evaluating on Test Set ---\")\n    test_time = evaluate_model(model, dataloaders['test'], class_names)\n    print(\"\\n--- Generating Accuracy Plot ---\")\n    plt.figure(figsize=(10, 6))\n    plt.plot(range(1, NUM_EPOCHS + 1), train_acc, 'b-o', label='Training Accuracy')\n    plt.plot(range(1, NUM_EPOCHS + 1), val_acc, 'r-o', label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:38:34.839466Z","iopub.execute_input":"2025-08-12T07:38:34.839791Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nFound 5 classes.\nDataset sizes: {'train': 17500, 'val': 3750, 'test': 3750}\nClass names: ['cervix_dyk', 'cervix_koc', 'cervix_mep', 'cervix_pab', 'cervix_sfi']\nPre-trained weights loaded successfully from file.\n\nEpoch 0/9\n----------\nTrain Loss: 0.5374 Acc: 0.8333\nVal Loss: 0.2526 Acc: 0.9275\nBest validation accuracy! Model saved.\n\nEpoch 1/9\n----------\nTrain Loss: 0.3303 Acc: 0.8855\nVal Loss: 0.1867 Acc: 0.9469\nBest validation accuracy! Model saved.\n\nEpoch 2/9\n----------\nTrain Loss: 0.2888 Acc: 0.8988\n","output_type":"stream"}],"execution_count":null}]}